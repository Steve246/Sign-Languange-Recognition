# -*- coding: utf-8 -*-
"""SIgn Languange Classifier 2.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VdrXK4dK5mBOpsO01oZHRLvzKKmDL9ga
"""

import os
from google.colab import drive
MOUNTPOINT = '/content/gdrive'
drive.mount(MOUNTPOINT)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

# Kita ambil Test dan Train data
train = pd.read_csv('/content/drive/MyDrive/Dataset Sign Languange/sign_mnist_train.csv') 
test = pd.read_csv('/content/drive/MyDrive/Dataset Sign Languange/sign_mnist_test.csv')

# Liat isi dalemnya
train.head()

"""# Cek Isi Dataset yang kita punya"""

# Ambil label
labels = train['label'].values

labels = train['label'].values

jumlahA = 0
jumlahB = 0
jumlahC = 0
jumlahD = 0
jumlahE = 0
jumlahF = 0
jumlahG = 0
jumlahH = 0
jumlahI = 0
jumlahK = 0
jumlahL = 0
jumlahM = 0
jumlahN = 0
jumlahO = 0
jumlahP = 0
jumlahQ = 0
jumlahR = 0
jumlahS = 0
jumlahT = 0
jumlahU = 0
jumlahV = 0
jumlahW = 0
jumlahX = 0
jumlahQ = 0
jumlahY = 0


for x in labels:
  if x == 0:
    jumlahA += 1
  if x == 1:
    jumlahB += 1
  if x == 2:
    jumlahC += 1 
  if x == 3:
    jumlahD += 1
  if x == 4:
    jumlahE += 1
  if x == 5:
    jumlahF += 1
  if x == 6:
    jumlahG += 1
  if x == 7:
    jumlahH += 1
  if x == 8:
    jumlahI += 1
  if x == 10:
    jumlahK += 1
  if x == 11:
    jumlahL += 1
  if x == 12:
    jumlahM += 1
  if x == 13:
    jumlahN += 1
  if x == 14:
    jumlahO += 1

  if x == 15:
    jumlahP += 1
  if x == 16:
    jumlahQ += 1
  if x == 17:
    jumlahR += 1
  if x == 18:
    jumlahS += 1
  if x == 19:
    jumlahT += 1
  if x == 20:
    jumlahU += 1
  if x == 21:
    jumlahV += 1
  if x == 22:
    jumlahW += 1
  if x == 23:
    jumlahX += 1
  if x == 24:
    jumlahY += 1

print("Tidak ada J dan Z, pada dataset")
print("Jumlah A (0): ", jumlahA)
print("Jumlah B (1): ", jumlahB)
print("Jumlah C (2): ", jumlahC)
print("Jumlah D (3): ", jumlahD)
print("Jumlah E (4): ", jumlahE)

print("Jumlah F (5): ", jumlahF)
print("Jumlah G (6): ", jumlahG)
print("Jumlah H (7): ", jumlahH)
print("Jumlah I (8): ", jumlahI)

print("Jumlah K (10): ", jumlahK)
print("Jumlah L (11): ", jumlahL)
print("Jumlah M (12): ", jumlahM)
print("Jumlah N (13): ", jumlahN)
print("Jumlah O (14): ", jumlahO)

print("Jumlah P (15): ", jumlahP)
print("Jumlah Q (16): ", jumlahQ)
print("Jumlah R (17): ", jumlahR)
print("Jumlah S (18): ", jumlahS)

print("Jumlah T (19): ", jumlahT)
print("Jumlah U (20): ", jumlahU)
print("Jumlah V (21): ", jumlahV)
print("Jumlah W (22): ", jumlahW)

print("Jumlah X (23): ", jumlahX)
print("Jumlah Y (24): ", jumlahY)

# View the unique labels, 24 in total (no 9 , and no 25)
unique_val = np.array(labels)
np.unique(unique_val)

# Plot the quantities in each class
plt.figure(figsize = (18,8))
sns.countplot(x = labels)

"""# Pisahin Label dan Pixel Value"""

train_ToNumpy = train.to_numpy()
images = train_ToNumpy[:, 1:] 
print(images.shape)

# hot one encode our labels
from sklearn.preprocessing import LabelBinarizer
label_binrizer = LabelBinarizer()
labels = label_binrizer.fit_transform(labels)

# View our labels
labels
# len(labels[0])

labels.shape

"""visualisasi"""

# Inspect an image
index = 0
print(labels[index])
plt.imshow(images[index].reshape(28,28))

# Use OpenCV to view 10 random images from our training data

from google.colab.patches import cv2_imshow, cv2
for i in range(0,10):
    rand = np.random.randint(0, len(images))
    input_im = images[rand]

    sample = input_im.reshape(28,28).astype(np.uint8)
    sample = cv2.resize(sample, None, fx=10, fy=10, interpolation = cv2.INTER_CUBIC)
    cv2_imshow(sample) #only take one argument
    cv2.waitKey(0) 
    
cv2.destroyAllWindows()

"""Split process"""

# Split our data into x_train, x_test, y_train and y_test
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(images, labels, 
                                                    test_size = 0.3, 
                                                    random_state = 1)

print(x_train)

print(y_train)

# Scale our images
x_train = x_train / 255
x_test = x_test / 255
print(x_train)

# Reshape them into the size required by TF and Keras
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)


plt.imshow(x_train[0].reshape(28,28))

print(x_train.shape)

print(x_test.shape)

# Start loading our tensorFlow modules and define our batch size etc
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout
import tensorflow as tf

batch_size = 64
num_classes = 24
epochs = 10

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.92):
      print("\nAkurasi telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

# Create our CNN Model

model = tf.keras.models.Sequential([
tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),
tf.keras.layers.MaxPooling2D(2,2),

tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2), 

tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),      

tf.keras.layers.Flatten(),
tf.keras.layers.Dense(128, activation='relu'),

tf.keras.layers.Dropout(0.20)

])

model.add(Dense(num_classes, activation = 'softmax'))

model.summary()

model.compile(loss = 'categorical_crossentropy',
              optimizer= 'adam',
              metrics=['accuracy'])

# Train our Model
history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size, callbacks = [callbacks])

# View our training history graphically
plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
plt.plot(history.history['loss'], label='Loss')
plt.plot(history.history['val_loss'], label='val_Loss')
plt.legend()
plt.grid()
plt.title('Loss evolution')

plt.subplot(2, 2, 2)
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.legend()
plt.grid()
plt.title('Accuracy evolution')

# Reshape  test data yang kita dapat supaya bisa di evaluate perfomanya
test_labels2 = test['label']
test.drop('label', axis = 1, inplace = True)

test_images2 = test.values
test_images2 = np.array([np.reshape(i, (28, 28)) for i in test_images2])
test_images2 = np.array([i.flatten() for i in test_images2])

test_labels2 = label_binrizer.fit_transform(test_labels2)

test_images2 = test_images2.reshape(test_images2.shape[0], 28, 28, 1)

test_images2.shape

y_pred = model.predict(test_images2)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(test_labels2,  y_pred.round())
print('Accuracy: %f' % accuracy)

precision = precision_score(test_labels2,  y_pred.round(), average = 'weighted')
print('Precision: %f' % precision)
# precision tp / (tp + fp)

recall = recall_score(test_labels2, y_pred.round(), average = 'weighted')
print('Recall: %f' % recall)
# recall: tp / (tp + fn)

f1 = f1_score(test_labels2, y_pred.round(), average = 'weighted')
print('F1 score: %f' % f1)
# f1: 2 tp / (2 tp + fp + fn)

"""# Confusion Matrix"""

from sklearn.metrics import confusion_matrix
from sklearn import metrics
cm = metrics.confusion_matrix(test_labels2.argmax(axis = 1), y_pred.argmax(axis = 1))

def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Computing confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

# Visualizing
    fig, ax = plt.subplots(figsize=(10, 10))
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

   # Rotating the tick labels and setting their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")
    # Looping over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax
np.set_printoptions(precision=2)

class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]

plt.figure(figsize=(20,20))
plot_confusion_matrix(test_labels2.argmax(axis = 1), y_pred.argmax(axis = 1), classes = class_names, title='Non-Normalized Confusion matrix')
plt.show()

plt.figure(figsize=(40,40))
plot_confusion_matrix(test_labels2.argmax(axis = 1), y_pred.argmax(axis = 1), classes = class_names, normalize=True, title='Normalized Confusion matrix')
plt.show()

"""# OpenCV Part"""

# Create function to match label to letter
def getLetter(result):
    classLabels = { 0: 'A',
                    1: 'B',
                    2: 'C',
                    3: 'D',
                    4: 'E',
                    5: 'F',
                    6: 'G',
                    7: 'H',
                    8: 'I',
                    9: 'K',
                    10: 'L',
                    11: 'M',
                    12: 'N',
                    13: 'O',
                    14: 'P',
                    15: 'Q',
                    16: 'R',
                    17: 'S',
                    18: 'T',
                    19: 'U',
                    20: 'V',
                    21: 'W',
                    22: 'X',
                    23: 'Y'}
    try:
        res = int(result)
        return classLabels[res]
    except:
        return "Error"

import cv2

cap = cv2.VideoCapture(0)

while True:

    ret, frame = cap.read()
    
    ##############################
    frame=cv2.flip(frame, 1)

    #define region of interest
    roi = frame[100:400, 320:620]
    cv2.imshow('roi', roi)
    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    roi = cv2.resize(roi, (28, 28), interpolation = cv2.INTER_AREA)
    
    cv2.imshow('roi sacled and gray', roi)
    copy = frame.copy()
    cv2.rectangle(copy, (320, 100), (620, 400), (255,0,0), 5)
    
    roi = roi.reshape(1,28,28,1) 

    result = str(model.predict_classes(roi, 1, verbose = 0)[0])
    cv2.putText(copy, getLetter(result), (300 , 100), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 255, 0), 2)
    cv2.imshow('frame', copy)    
    
    if cv2.waitKey(1) == 13: #13 is the Enter Key
        break
        
cap.release()
cv2.destroyAllWindows()